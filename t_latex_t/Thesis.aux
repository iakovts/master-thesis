\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Declaration of Authorship}{i}{dummy.2}\protected@file@percent }
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Abstract}{iii}{dummy.3}\protected@file@percent }
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iv}{dummy.4}\protected@file@percent }
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vii}{dummy.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{viii}{dummy.8}\protected@file@percent }
\gdef \LT@i {\LT@entry 
    {1}{58.36221pt}\LT@entry 
    {1}{104.06738pt}}
\@writefile{toc}{\contentsline {chapter}{Abbreviations}{ix}{dummy.10}\protected@file@percent }
\citation{book:2008}
\citation{book:2008}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{1}{Introduction}{chapter.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Graphs}{1}{section.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Introduction}{1}{subsection.15}\protected@file@percent }
\newlabel{u_simple_graph}{{1.1}{1}{}{theorem.16}{}}
\citation{article:bollobas}
\citation{book:Gary}
\newlabel{graph_def}{{1.2}{2}{}{theorem.18}{}}
\newlabel{eq:phi}{{1.1}{2}{}{equation.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces An undirected pseudograph with labeled nodes and edges.\relax }}{2}{figure.caption.20}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:SimplePseudograph}{{1.1}{2}{An undirected pseudograph with labeled nodes and edges.\relax }{figure.caption.20}{}}
\newlabel{fig:simple_adj_demo}{{1.2a}{4}{Multigraph with no loops and multiple edges.\relax }{figure.caption.26}{}}
\newlabel{sub@fig:simple_adj_demo}{{a}{4}{Multigraph with no loops and multiple edges.\relax }{figure.caption.26}{}}
\newlabel{fig:compl_adj_demo}{{1.2b}{4}{Mutligraph with loops and multiple edges.\relax }{figure.caption.26}{}}
\newlabel{sub@fig:compl_adj_demo}{{b}{4}{Mutligraph with loops and multiple edges.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Two undirected multigraphs.\relax }}{4}{figure.caption.26}\protected@file@percent }
\newlabel{fig:two multigraphs}{{1.2}{4}{Two undirected multigraphs.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Adjacency Matrix}{4}{subsection.23}\protected@file@percent }
\newlabel{eq:adj_mat}{{1.2}{4}{}{equation.25}{}}
\citation{book:algebraic}
\citation{book:Newman}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Adjacency matrix for Figure\nobreakspace  {}\ref  {fig:simple_adj_demo}\relax }}{5}{table.caption.27}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces Adjacency matrix for Figure\nobreakspace  {}\ref  {fig:compl_adj_demo}\relax }}{5}{table.caption.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2.1}Adjacency List}{6}{subsubsection.30}\protected@file@percent }
\newlabel{table:adj_list_ex}{{\caption@xref {table:adj_list_ex}{ on input line 249}}{6}{Adjacency List}{table.caption.31}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces Adjacency list for Figure\nobreakspace  {}\ref  {fig:compl_adj_demo}\relax }}{6}{table.caption.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Graph Laplacian}{6}{subsection.33}\protected@file@percent }
\newlabel{sec:laplacian}{{1.1.3}{6}{Graph Laplacian}{subsection.33}{}}
\citation{article:ChebNet}
\citation{book:Newman}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Edge weights}{7}{subsection.34}\protected@file@percent }
\newlabel{sec:edge_weights}{{1.1.4}{7}{Edge weights}{subsection.34}{}}
\newlabel{fig:simple_adj_demo}{{1.3a}{7}{Multigraph with no loops and multiple edges.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:simple_adj_demo}{{a}{7}{Multigraph with no loops and multiple edges.\relax }{figure.caption.35}{}}
\newlabel{table:weighted_adj}{{1.3b}{7}{Corresponding adjacency matrix.\relax }{figure.caption.35}{}}
\newlabel{sub@table:weighted_adj}{{b}{7}{Corresponding adjacency matrix.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Simple example of an unordered graph with weighted edges\relax }}{7}{figure.caption.35}\protected@file@percent }
\newlabel{fig:weighted_graph}{{1.3}{7}{Simple example of an unordered graph with weighted edges\relax }{figure.caption.35}{}}
\citation{book:Newman}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.5}Distance between nodes and shortest paths}{8}{subsection.36}\protected@file@percent }
\newlabel{table:weighted_adj}{{\caption@xref {table:weighted_adj}{ on input line 389}}{8}{}{figure.caption.39}{}}
\newlabel{sub@table:weighted_adj}{{}{8}{}{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces A graph with a maximum path of 3 (nodes 1 to 6).\relax }}{8}{figure.caption.39}\protected@file@percent }
\newlabel{fig:weighted_graph}{{1.4}{8}{A graph with a maximum path of 3 (nodes 1 to 6).\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.6}Node and edge properties}{9}{subsection.40}\protected@file@percent }
\newlabel{table:properties_example}{{\caption@xref {table:properties_example}{ on input line 467}}{10}{}{figure.caption.42}{}}
\newlabel{sub@table:properties_example}{{}{10}{}{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Example graph of a small classroom with labeled edges and nodes\relax }}{10}{figure.caption.42}\protected@file@percent }
\newlabel{fig:properties_example}{{1.5}{10}{Example graph of a small classroom with labeled edges and nodes\relax }{figure.caption.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.4}{\ignorespaces A) Node properties B) Edge properties\relax }}{10}{table.caption.43}\protected@file@percent }
\newlabel{tbl:Node and edge properties}{{1.4}{10}{A) Node properties B) Edge properties\relax }{table.caption.43}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.5}{\ignorespaces Graph Properties\relax }}{10}{table.caption.44}\protected@file@percent }
\citation{book:Jost2007}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Network Dynamics}{11}{section.45}\protected@file@percent }
\citation{article:McCulloch1943}
\citation{article:Rosenblatt1958ThePA}
\citation{book:minsky1969perceptrons}
\citation{book:werbos1975beyond}
\citation{article:Cresceptron}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Graph Neural Networks}{12}{chapter.46}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{literature}{{2}{12}{Graph Neural Networks}{chapter.46}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Background - Artificial Neural Networks}{12}{section.47}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Introduction}{12}{subsection.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.1}Historical Background}{12}{subsubsection.49}\protected@file@percent }
\citation{book:Gurney1997AnIT}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Basics}{13}{subsection.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.1}Summary}{13}{subsubsection.55}\protected@file@percent }
\citation{article:SCHMID}
\citation{article:SCHMID}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A simple neural network demonstrating the layered structure and and flow of data from input to output.\relax }}{14}{figure.caption.56}\protected@file@percent }
\newlabel{fig:simple_nn_demo}{{2.1}{14}{A simple neural network demonstrating the layered structure and and flow of data from input to output.\relax }{figure.caption.56}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.2}Building Blocks}{14}{subsubsection.57}\protected@file@percent }
\citation{article:Rosenblatt1958ThePA}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Input to a single neuron in a feedforward network. Here $\sigma $ represents the activation function (a sigmoid function in this case) and the exponents represent layers. The activation of a layer can be conveniently represented in matrix form. Biases are added to the input of the node.\relax }}{15}{figure.caption.59}\protected@file@percent }
\newlabel{fig:nn_activation}{{2.2}{15}{Input to a single neuron in a feedforward network. Here $\sigma $ represents the activation function (a sigmoid function in this case) and the exponents represent layers. The activation of a layer can be conveniently represented in matrix form. Biases are added to the input of the node.\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.3}Feedforward Networks}{15}{subsubsection.60}\protected@file@percent }
\citation{book:Goodfellow}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.4}Perceptrons, learning algorithms and simple NNs}{16}{subsubsection.61}\protected@file@percent }
\newlabel{sec:perceptron}{{2.1.2.4}{16}{Perceptrons, learning algorithms and simple NNs}{subsubsection.61}{}}
\newlabel{fig:simple_perceptron}{{\caption@xref {fig:simple_perceptron}{ on input line 205}}{17}{Perceptrons, learning algorithms and simple NNs}{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A simple perceptron\relax }}{17}{figure.caption.62}\protected@file@percent }
\citation{book:Abramowitz}
\citation{book:Goodfellow}
\citation{article:Cauchy}
\newlabel{eq:sigmoid}{{2.1}{18}{Learning Algorithms}{equation.66}{}}
\newlabel{fig:sigmoid function and its derivative}{{\caption@xref {fig:sigmoid function and its derivative}{ on input line 295}}{18}{Learning Algorithms}{figure.caption.65}{}}
\newlabel{sub@fig:sigmoid function and its derivative}{{a}{18}{Learning Algorithms}{figure.caption.65}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Mathematics of Artificial Neural Networks}{18}{section.67}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Gradient Descent}{18}{subsection.68}\protected@file@percent }
\newlabel{sec:gradient_descent}{{2.2.1}{18}{Gradient Descent}{subsection.68}{}}
\citation{book:optimization}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Gradient descent in three dimensional space\relax }}{19}{figure.caption.70}\protected@file@percent }
\newlabel{fig:gradient_descent_2d}{{2.5}{19}{Gradient descent in three dimensional space\relax }{figure.caption.70}{}}
\newlabel{eq:grad_simple}{{2.2}{19}{}{equation.72}{}}
\newlabel{eq:convex_func}{{2.3}{19}{}{equation.74}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Stochastic Gradient Descent (SGD)}{20}{subsection.75}\protected@file@percent }
\newlabel{sec:stoch_grad_desc}{{2.2.2}{20}{Stochastic Gradient Descent (SGD)}{subsection.75}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Types of the most common ANNs}{21}{subsection.76}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Training}{21}{subsection.78}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Convolutional Neural Networks}{22}{subsection.79}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Notation \& Fundamentals}{23}{chapter.80}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{methodology}{{3}{23}{Notation \& Fundamentals}{chapter.80}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Basic Principles and Implementation Framework for an [Problem to be Solved]}{24}{chapter.81}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{framework}{{4}{24}{Basic Principles and Implementation Framework for an [Problem to be Solved]}{chapter.81}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Implementation and Core Components of [Platform Title]}{25}{chapter.82}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{platform}{{5}{25}{Implementation and Core Components of [Platform Title]}{chapter.82}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Experimentation \& Validation}{26}{chapter.83}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{experimentationANDresults}{{6}{26}{Experimentation \& Validation}{chapter.83}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions \& Future Work}{27}{chapter.84}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusions}{{7}{27}{Conclusions \& Future Work}{chapter.84}{}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\vspace  {2em}}
\bibstyle{unsrtnat}
\bibdata{Bibliography}
\bibcite{book:2008}{{1}{2008}{{Adrian~Bondy}}{{}}}
\bibcite{article:bollobas}{{2}{2002}{{Bollobas and Szemerédi}}{{}}}
\bibcite{book:Gary}{{3}{2012}{{Gary~Chartrand}}{{}}}
\bibcite{book:algebraic}{{4}{}{{Ashikhmin and Barg}}{{}}}
\bibcite{book:Newman}{{5}{2018}{{Newman}}{{}}}
\bibcite{article:ChebNet}{{6}{2016}{{Defferrard et~al.}}{{Defferrard, Bresson, and Vandergheynst}}}
\bibcite{book:Jost2007}{{7}{2007}{{Jost}}{{}}}
\bibcite{article:McCulloch1943}{{8}{1943}{{McCulloch and Pitts}}{{}}}
\bibcite{article:Rosenblatt1958ThePA}{{9}{1958}{{Rosenblatt}}{{}}}
\bibcite{book:minsky1969perceptrons}{{10}{1969}{{Minsky and Papert}}{{}}}
\bibcite{book:werbos1975beyond}{{11}{1975}{{Werbos}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{28}{dummy.85}\protected@file@percent }
\newlabel{Bibliography}{{7}{28}{Conclusions \& Future Work}{dummy.85}{}}
\bibcite{article:Cresceptron}{{12}{1992}{{Weng et~al.}}{{Weng, Ahuja, and Huang}}}
\bibcite{book:Gurney1997AnIT}{{13}{1997}{{Gurney}}{{}}}
\bibcite{article:SCHMID}{{14}{2015}{{Schmidhuber}}{{}}}
\bibcite{book:Goodfellow}{{15}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, and Courville}}}
\bibcite{article:Cauchy}{{16}{1847}{{Cauchy}}{{}}}
\bibcite{book:optimization}{{17}{2005}{{Liqun~Qi}}{{}}}
