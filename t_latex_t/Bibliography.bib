@book{book:2008,
   title =     {Graph theory},
   author =    {Adrian Bondy, U.S.R. Murty},
   publisher = {Springer},
   isbn =      {1846289696; 9781846289699},
   year =      {2008},
   series =    {Graduate texts in mathematics 244},
   edition =   {3rd Corrected Printing.},
   }

@article{article:bollobas,
author = {Bollobas, Bela and Szemerédi, Endre},
year = {2002},
month = {01},
pages = {194 - 200},
title = {Girth of Sparse Graphs},
volume = {39},
journal = {Journal of Graph Theory},
doi = {10.1002/jgt.10023}
}

@book{book:Gary,
   title =     {A First Course in Graph Theory},
   author =    {Gary Chartrand, Ping Zhang},
   publisher = {Dover Publications},
   isbn =      {0486483681; 9780486483689},
   year =      {2012},
   series =    {Dover Books on Mathematics},
}

@book{book:Newman,
   title =     {Networks},
   author =    {Mark Newman},
   publisher = {Oxford University Press},
   isbn =      {0198805098; 9780198805090},
   year =      {2018},
   edition =   {2},
}

@book{book:algebraic,
  title={Algebraic Coding Theory and Information Theory: DIMACS Workshop, Algebraic Coding Theory and Information Theory, December 15-18, 2003, Rutgers University, Piscataway, New Jersey},
  author={Ashikhmin, A. and Barg, A.},
  isbn={9780821871102},
  series={DIMACS series in discrete mathematics and theoretical computer science},
  url={https://books.google.gr/books?id=wp7XsCAm\_9EC},
  publisher={American Mathematical Soc.}
}
@article{article:TGNNM,
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE Transactions on Neural Networks}, 
  title={The Graph Neural Network Model}, 
  year={2009},
  volume={20},
  number={1},
  pages={61-80},
  doi={10.1109/TNN.2008.2005605}}


@Inbook{book:Jost2007,
author="Jost, J{\"u}rgen",
title="Dynamical Networks",
bookTitle="Networks: From Biology to Theory",
year="2007",
publisher="Springer London",
address="London",
pages="35--62",
abstract="The theory of dynamical networks is concerned with systems of dynamical units coupled according to an underlying graph structure. It therefore investigates the interplay between dynamics and structure, between the temporal processes going on at the individual units and the static spatial structure linking them. In order to analyse that spatial structure, formalized as a graph, we discuss an essentially complete system of graph invariants, the spectrum of the graph Laplacian, and how it relates to various qualitative properties of the graph. We also describe various stochastic construction schemes for graphs with certain qualitative features. We then turn to dynamical aspects and discuss systems of oscillators with diffusive coupling according to the graph Laplacian and analyse their synchronizability. The analytical tool here are local expansions in terms of eigenmodes of the graph Laplacian. This is viewed as a first step towards a general understanding of pattern formation in systems of coupled oscillators.",
isbn="978-1-84628-780-0",
doi="10.1007/978-1-84628-780-0_3",
url="https://doi.org/10.1007/978-1-84628-780-0_3"
}


@article{article:ChebNet,
author = {Defferrard, Michaël and Bresson, Xavier and Vandergheynst, Pierre},
year = {2016},
month = {06},
title = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering}
}
@article{article:kermack,
  author = {Kermack, W. O. and McKendrick, A. G.},
  month = {08},
  pages = {700-721},
  title = {A Contribution to the Mathematical Theory of Epidemics},
  doi = {10.1098/rspa.1927.0118},
  volume = {115},
  year = {1927},
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences}
}
@book{book:Goodfellow,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{article:McCulloch1943,
	volume = {5},
	number = {4},
	doi = {10.1007/bf02478259},
	title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
	author = {Warren S. McCulloch and Walter Pitts},
	journal = {The Bulletin of Mathematical Biophysics},
	pages = {115--133},
	year = {1943}
}

@book{book:Gurney1997AnIT,
  title={An introduction to neural networks},
  author={Kevin N. Gurney},
  year={1997}
}

@article{article:Rosenblatt1958ThePA,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Frank Rosenblatt},
  journal={Psychological review},
  year={1958},
  volume={65 6},
  pages={
          386-408
        }
}
@book{book:minsky1969perceptrons,
  title={Perceptrons; an Introduction to Computational Geometry},
  author={Minsky, M. and Papert, S.},
  isbn={9780262630221},
  lccn={69014379},
  url={https://books.google.gr/books?id=Ow1OAQAAIAAJ},
  year={1969},
  publisher={MIT Press}
}

@book{book:werbos1975beyond,
  title={Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences},
  author={Werbos, P.J.},
  url={https://books.google.gr/books?id=z81XmgEACAAJ},
  year={1975},
  publisher={Harvard University}
}

@INPROCEEDINGS{article:Cresceptron,

  author={Weng, J. and Ahuja, N. and Huang, T.S.},

  booktitle={[Proceedings 1992] IJCNN International Joint Conference on Neural Networks}, 

  title={Cresceptron: a self-organizing neural network which grows adaptively}, 

  year={1992},

  volume={1},

  number={},

  pages={576-581 vol.1},

  doi={10.1109/IJCNN.1992.287150}}

@article{article:SCHMID,
title = {Deep learning in neural networks: An overview},
journal = {Neural Networks},
volume = {61},
pages = {85-117},
year = {2015},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2014.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608014002135},
author = {Jürgen Schmidhuber},
keywords = {Deep learning, Supervised learning, Unsupervised learning, Reinforcement learning, Evolutionary computation},
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.}
}