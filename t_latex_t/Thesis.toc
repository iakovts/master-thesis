\contentsline {chapter}{Abstract}{i}{dummy.2}%
\vspace {1em}
\contentsline {chapter}{Acknowledgements}{ii}{dummy.3}%
\vspace {1em}
\contentsline {chapter}{List of Figures}{v}{dummy.5}%
\contentsline {chapter}{List of Tables}{vi}{dummy.7}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.9}%
\contentsline {section}{\numberline {1.1}Graphs}{1}{section.10}%
\contentsline {subsection}{\numberline {1.1.1}Introduction}{1}{subsection.11}%
\contentsline {subsection}{\numberline {1.1.2}Adjacency Matrix}{4}{subsection.19}%
\contentsline {subsubsection}{\numberline {1.1.2.1}Adjacency List}{6}{subsubsection.26}%
\contentsline {subsection}{\numberline {1.1.3}Graph Laplacian}{7}{subsection.29}%
\contentsline {subsection}{\numberline {1.1.4}Edge weights}{7}{subsection.30}%
\contentsline {subsection}{\numberline {1.1.5}Distance between nodes and shortest paths}{8}{subsection.32}%
\contentsline {subsection}{\numberline {1.1.6}Node and edge properties}{9}{subsection.36}%
\contentsline {section}{\numberline {1.2}Network Dynamics}{12}{section.41}%
\contentsline {subsection}{\numberline {1.2.1}Simple Contagion Dynamics (SIS)}{12}{subsection.42}%
\contentsline {subsection}{\numberline {1.2.2}Complex Contagion Dynamics --- Planck SIS}{13}{subsection.46}%
\contentsline {section}{\numberline {1.3}Models of network formation}{13}{section.49}%
\contentsline {subsection}{\numberline {1.3.1}The Barab{\'a}si-Albert Model}{14}{subsection.50}%
\contentsline {subsection}{\numberline {1.3.2}Erd{\H {o}}s-R{\'e}nyi Model}{14}{subsection.52}%
\contentsline {chapter}{\numberline {2}Neural Networks}{15}{chapter.54}%
\contentsline {section}{\numberline {2.1}Historical Background}{15}{section.55}%
\contentsline {subsection}{\numberline {2.1.1}Basics}{16}{subsection.60}%
\contentsline {subsubsection}{\numberline {2.1.1.1}Summary}{16}{subsubsection.61}%
\contentsline {subsubsection}{\numberline {2.1.1.2}Building Blocks}{17}{subsubsection.63}%
\contentsline {section}{\numberline {2.2}Mathematics useful in ANNs}{18}{section.65}%
\contentsline {subsection}{\numberline {2.2.1}Gradient Descent}{18}{subsection.66}%
\contentsline {subsection}{\numberline {2.2.2}Hadamard Product}{20}{subsection.73}%
\contentsline {section}{\numberline {2.3}Feedforward Networks}{20}{section.75}%
\contentsline {subsection}{\numberline {2.3.1}Perceptrons, learning algorithms and simple NNs}{21}{subsection.76}%
\contentsline {subsection}{\numberline {2.3.2}Backpropagation}{26}{subsection.96}%
\contentsline {subsection}{\numberline {2.3.3}Common ANN Architectures}{31}{subsection.120}%
\contentsline {subsubsection}{\numberline {2.3.3.1}Convolutional Neural Networks (CNNs)}{31}{subsubsection.121}%
\contentsline {subsubsection}{\numberline {2.3.3.2}Recurrent Neural Networks (RNNs)}{33}{subsubsection.125}%
\contentsline {chapter}{\numberline {3}Graph Neural Networks (GNNs)}{34}{chapter.126}%
\contentsline {section}{\numberline {3.1}Introduction}{34}{section.127}%
\contentsline {section}{\numberline {3.2}From CNNs to Graph Neural Networks}{37}{section.130}%
\contentsline {subsection}{\numberline {3.2.1}Challenges}{37}{subsection.131}%
\contentsline {subsection}{\numberline {3.2.2}Creating embeddings}{37}{subsection.132}%
\contentsline {subsection}{\numberline {3.2.3}Initial Implementations}{38}{subsection.139}%
\contentsline {subsubsection}{\numberline {3.2.3.1}Algorithmic Computation using polynomials}{40}{subsubsection.147}%
\contentsline {section}{\numberline {3.3}Modern Graph Neural Networks}{41}{section.151}%
\contentsline {subsection}{\numberline {3.3.1}Embeddings}{41}{subsection.152}%
\contentsline {subsection}{\numberline {3.3.2}Learning}{43}{subsection.156}%
\contentsline {chapter}{\numberline {4}Experiments and Results}{44}{chapter.158}%
\contentsline {section}{\numberline {4.1}Background}{44}{section.159}%
\contentsline {section}{\numberline {4.2}Fundamental ideas of this approach}{44}{section.160}%
\contentsline {section}{\numberline {4.3}Description of goals}{45}{section.163}%
\contentsline {section}{\numberline {4.4}Architecture of the GNN}{46}{section.167}%
\contentsline {subsection}{\numberline {4.4.1}Structure}{46}{subsection.168}%
\contentsline {subsection}{\numberline {4.4.2}Attention Mechanism}{47}{subsection.173}%
\contentsline {subsection}{\numberline {4.4.3}Loss Function}{48}{subsection.176}%
\contentsline {subsection}{\numberline {4.4.4}Benchmarking and performance}{48}{subsection.178}%
\contentsline {section}{\numberline {4.5}Experiments}{48}{section.180}%
\contentsline {subsection}{\numberline {4.5.1}Generating Data}{49}{subsection.181}%
\contentsline {subsection}{\numberline {4.5.2}SIS}{49}{subsection.182}%
\contentsline {subsection}{\numberline {4.5.3}Planck SIS}{50}{subsection.184}%
\contentsline {section}{\numberline {4.6}Discussion of results}{52}{section.186}%
\vspace {2em}
\contentsline {chapter}{\numberline {A}Transformers and self-attention}{53}{appendix.187}%
\contentsline {section}{\numberline {A.1}Attention and self-attention}{53}{section.188}%
\contentsline {section}{\numberline {A.2}Attention in Graph Attention Networks}{54}{section.190}%
\contentsline {chapter}{\numberline {B}Additional Results}{56}{appendix.195}%
\contentsline {section}{\numberline {B.1}SIS on a $G(n, p)$ network}{56}{section.196}%
\vspace {2em}
\contentsline {chapter}{Bibliography}{58}{dummy.198}%
