\chapter{Graph Neural Networks} \label{literature}

\section{Background - Artificial Neural Networks}

\subsection{Introduction}

\subsubsection{Historical Background}

\textbf{Artificial Neural Networks (ANN)}, or sometimes simply called
\textbf{neural networks} is a class of computational models that mimic
the way biological neural networks work, such as the human brain. Interest
on the subject sparked after the seminal paper \textit{"A Logical
Calculus of the Ideas Immanent in Nervous Activity"}
\cite{article:McCulloch1943} by Warren McCulloch and Walter Pitts, where
they proposed a computationally functional model of neural networks.
Their suggestions showed that in principle, any function a digital computer
can compute, a neural net should too. The models they described had weights
and thresholds, but they lacked a training method. 

The suggestions of McCulloch and Pitts lead Frank Rosenblatt to create
the \textit{Perceptron} in 1958 \cite{article:Rosenblatt1958ThePA}, a
binary classifier algorithm based on supervised
learning\footnote{Supervised learning is a machine learning training
technique that optimizes a model based on examples input-output
pairs.}. Although initially promising, single layer perceptrons were
not able to train on multiple classes of patterns and were eventually
proven incapable of learning a XOR function \footnote{XOR (Exclusive
or, $x\oplus y$) is a logical operation that is true only if its
arguments differ.} in the book \textit{Perceptrons}
\cite{book:minsky1969perceptrons}, as the way they worked was by
``separating'' data linearly. This lead to a stagnation in machine
learning research dubbed ``AI winter'', until the proposal of
\textbf{backpropagation\footnote{Backpropagation is a method of fine
tuning a neural network based on the error rate obtained from previous
runs of the program. It will be discussed in detail later in this
thesis.}} by Paul John Werbos in 1975 \cite{book:werbos1975beyond}.

A renewed interest in the field lead to the development of the
Cresceptron \cite{article:Cresceptron} in 1992, a method of training
large networks with pooling layers (\textbf{max-pooling}) and down-sampling.
GPU\footnote{GPU - Graphics Processing Units is a specialized
electronic circuit, a central part of modern computers which excels in
efficient computation of algorithms which process large blocks of data
parallelly, thus exceling in machine learning applications.} usage made
possible the training of larger networks, while new types of networks
emerged such as the \textbf{Recurrent Neural Networks (RNNs)}.
\textbf{Convolutional Neural Networks} have recently proven to be
far superior for image classification tasks.

In recent years, neural 


\subsection{Basics}
\subsubsection{Summary}

One can think of ANNs as a directed graph, with a collection of nodes
which are densely connected (called \textbf{artificial neurons}),
transimiting signals to each other. These nodes are usually organized
in sets of layers, with signals moving in one direction
(i.e. \textit{feed forward networks}) through weighted connections.
Signals received on a single neuron are real numbers, and the output
of a single neuron is the output of an aggregation of a non-linear
function of the sum of its inputs. This function is called an
\textit{activation function} and its results are propagated to all of
the nodes outgoing connections.  Thus, each neuron can be thought as a
simple processing unit. The weighted connections between nodes might
have an excitatory or inhibitory effect, based on these weights which
can be positive, negative or very close to zero, having no effect
\cite[Chap. ~ 1]{book:Gurney1997AnIT}. While training, example
data is passed through the input layer and gets radically transformed
through the layers until it reaches the output layer. The weights and
other trainable parameters are then adjusted until the training data
consistently reaches satisfactory results.

\begin{figure}[h!]
  \centering
  % \input{tikz_figures/chap_nn/node_activation.tex}
  \scalebox{.8}{\input{tikz_figures/chap_nn/simple_net.tex}}
  \caption{A simple neural network demonstrating the layered structure and
  and flow of data from input to output.}
  \label{fig:simple_nn_demo}
\end{figure}
\newpage
% \section{Backpropagation}
\subsubsection{Building Blocks}
% \begin{figure}[t!]
%   \centering
%   % \input{tikz_figures/chap_nn/node_activation.tex}
%   \scalebox{.8}{\input{tikz_figures/chap_nn/simple_nn_weighted.tex}}
%   \caption{A simple neural network demonstrating the layered structure and
%   and flow of data from input to output.}
%   \label{fig:nn_activation}
% \end{figure}

As mentioned before, the building blocks of ANNs are its artificial
neurons organized into layers. In  \fref{fig:simple_nn_demo} a basic
ANN is presented, demonstrating the different layers that are typically
present in a feedforward neural network \footnote{Feedforward Neural Networks
  (FNNs) are the simplest type of neural networks, with the information moving
  only in one direction (``forward'' through the layers), without any loops or
  cycles \cite{article:SCHMID}. Different types of neural networks are discussed
  later.} while the building blocks are widely considered \cite{article:SCHMID} to
be:
\begin{itemize}
\item \textbf{Input layer} This layer's purpose is to act as an
  entrypoint to the neural network and performs no computations. Data moves from
  this layer to the hidden layer succeeding it.
\item \textbf{Hidden layer} Networks typically have one or more
  hidden layers, in which some computation takes place. Data moves from the input
  layer to a hidden layer where it is transformed and together with its weights
  moves to the next hidden layer or the output layer.
\item \textbf{Output layer} Transformed data ``exits'' the network here,
  where it can pass through some function to reach the desired output
  format
\item \textbf{Edges and Weights} Each node in a layer is connected
  to a set (usually all) of the nodes of the following layer with a
  weighted edge. Signals from node $i$ of layer $k$ will be the input
  of node $j$ of layer $l$, multiplied by a weight $W_{ij}$. 
\item \textbf{Activation Functions} An activation function takes as
  input some form of aggregate (usually the weighted sum) of the signals
  arriving at a node and produces an output. This function is typically
  nonlinear and differentiable for reasons which will be discussed later.
\item \textbf{Learning} The learning process in a ANN involves modifying
  its weights and other learnable parameters to improve the accuracy
  of the result on the output layer. Learning usually involves a cost
  function which is evaluated on a predefined basis and adjustments are
  made accordingly. One of the most widespread learning techniques is
  \textit{backpropagation}, where the error is propagated backwards
  through the network.
  
\end{itemize}
Along with the data from previous layers aggregated at a neuron, a bias
is typically added which acts in the same way the intercept does in a
linear equation. It adjusts the output of the activation function along
with the weighted sum of the inputs to the neuron. It is also a trainable
constant value provided to each node of a layer. Biases are node level
parameters and do not depend on values provided by previous layers.

All of the computations that take place in layer can be represented in
a compact matrix form, as shown below.

\begin{figure}[h!]
  \centering
  % \input{tikz_figures/chap_nn/node_activation.tex}
  \scalebox{1}{\input{tikz_figures/chap_nn/nn_activation.tex}}
  \caption{Input to a single neuron in a feedforward network. Here
    $\sigma$ represents the activation function (a sigmoid function in
    this case) and the exponents represent layers. The activation of a
    layer can be conveniently represented in matrix form. Biases are added
    to the input of the node.}
  \label{fig:nn_activation}
\end{figure}

\subsubsection{Feedforward Networks}

\textbf{Feedforward neural networks (FNNs)} are the exemplary of ANNs, and the first to be
conceived and created by Rosenblatt in 1958 with the creation of the
perceptron \cite{article:Rosenblatt1958ThePA}. Their goal is to approximate
some function $f^{*}$; i.e. a classifier uses the function
$y=f^{*}(\bm{x})$ to map the input $\bm{x}$ to some category $y$. The
goal of a feedforward network would then be to define a mapping
$\bm{y} = f(\bm{x};~\bm{\theta})$ and train in a way that the values
of the parameter vector $\bm{\theta}$ provide the best approximation of
the function $f^{*}$.

These networks are called feedforward as information flows from the input layer
$\bm{x}$ through intermediate computational layers used to define $\bm{f}$ and
finally to the output $\bm{y}$. There are no loops providing (called
\textbf{feedback connections}) information from the output back into
the input or other intermediate layers of the network.

Feedforward networks can be thought as a chain of functions, composing
the final structure of the network. As an example, consider a network
with three of these functions as $f(\bm{x}) = f^{(3)}(f^{(2)}(f^{(1)}(\bm{x})))$.
In this case, the exponents denotes the layer, with $f^{(1)}$ beign the first
layer, $f^{(2)}$ the second etc. The total number of these functions is called
the \textbf{depth} of the NN and the terminology ``deep learning'' arose from
this layered structure.

During training the goal is to modify the parameters of the
network in a way that $f(\bm{x})$ closely matches $f^*(\bm{x})$. The training
set is composed of pairs of $\bm{x}$ and labels $y \approx f^*(\bm{x})$ and
the output of the network is evaluated at different training points. Training
data defines the exact result expected from each input $\bm{x}$, a value as close
as possible to $y$. The rest of the layers can have arbitary behaviours as long
as they transform the data in a way defined by the training goal. The
learning algorithm can ``use'' them in any way that is useful to it, and
the training data has no immediate effect on their behaviour. They are
thus called \textbf{``hidden layers''} as they do not produce any
meaningful result, related to the function \cite[p.~160]{book:Goodfellow}. 


% TODO: Describe deep learning (multiple layers?)
\subsubsection{Perceptrons, learning algorithms and simple NNs}\label{sec:perceptron}

The perceptron serves as great precursory example to
neural networks, as it introduces many concepts that are
common in more complex NN paradigms. Its in fact a simple
neuron, a computational unit, which takes a binary vector
as input and produces a binary output.

\begin{figure}[h!]
  \centering
  \input{tikz_figures/chap_nn/simple_perceptron.tex}
  \label{fig:simple_perceptron}
  \caption{A simple perceptron}
\end{figure}


Inputs are multiplied with \textit{weights}, and the output
of the neuron is either 0 or 1, determined by whether the
weighted sum of its inputs $\sum_i w_i a_i$ is greater than
a threshold value $threshold$. All of these numbers are real numbers
and a parameter of the neuron itself. The algebraic form of
this can be written as:



\begin{equation*}
  \text{Output} = \begin{cases}
    0 &\text{if } \sum_i w_i a_i \leq \text{threshold} \\
    1 &\text{if } \sum_i w_i a_i > \text{threshold}
  \end{cases}
\end{equation*}

By modifying the values of the threshold, the output
can be changed. The above equation can be written in
a more compact form by replacing the sums with the dot
product of the weights and the input vector,
$\sum_i w_i a_i = \bm{w} \cdot \bm{a}$. Moving
the threshold to the left side of the equation
and replacing it by what is referred to as the \textit{bias}
yields:

\begin{equation*}
  \text{Output} = \begin{cases}
    0 & if \bm{w} \cdot \bm{a} + b \leq 0 \\
    1 & if \bm{w} \cdot \bm{a} + b > 0
  \end{cases}
\end{equation*}

where $b$ = - threshold. The bias can be seen as a measure
of the tendency of the neuron to fire. Larger bias's numbers
makes the neuron easy to activate and output 1, while smaller
ones require larger inputs and positive weights. 

\begin{remark}
  As mentioned before, perceptrons are able to solve problems
  which are linearly seperatable with the slope represented
  by the $\bm{w} \cdot \bm{a}$ term and the bias acting as
  the intercept. 
  This excludes problems which are not, the most famous being
  the classic XOR gate, as there does not exist one single
  line capable of seperating the predictions.
\end{remark}

Multiple perceptrons can be combined in a network to compute any
logical function, including the XOR gate. These kind of NNs are called
\textit{multilayer perceptrons}, and they are the basis modern
artificial neural networks. As discussed before, these neuros (or
nodes) are organized in layers and can have a depth based on the
number of these layers. Typically, at least 3 layers are present.

\subsubsection*{Learning Algorithms}

So far, the way perceptrons transform data through a function
has been described, but while they can produce
sensible results as any other computing device, weights and
biases had to be manually configured. It is possible to introduce
a learning algorithm which does the tuning of these parameters
automatically, in response to input-output (training data) pairs.

The perceptrons described used the Heaviside step function
\cite{book:Abramowitz}, often denoted with $\textit{H}$. This function
has a binary nature, with its output value being 0 or 1 based on a
threshold, which presents a problem when fine tuning a perceptron or a
NN based on them. Minor changes in a weight or bias value can
completely alter the output trigger a perceptron to flip, and possibly
changing the output of the whole network. A better choice for an
activation function is the \textit{sigmoid function} $\sigma$ also
called the \textit{logistic function}.

\begin{figure}[h]
  \begin{subfigure}[t]{0.5\textwidth}
    \begin{equation}
      \sigma (x) = \frac{1}{1 + e^{-x}}
      \label{eq:sigmoid}
    \end{equation}
      \newline
      \caption{Mathematical definition of the sigmoid function.}
  \end{subfigure}
  \hfill
    \begin{subfigure}[c]{0.5\textwidth}
      \scalebox{0.65}{\input{tikz_figures/chap_nn/sigmoid_plot.tex}}
      \label{fig:sigmoid function and its derivative}
      \caption{Plot of the sigmoid function, its first derivative and
        the Heaviside step function.}
  \end{subfigure}

\end{figure}




\section{Mathematics of Artificial Neural Networks}

\subsection{Gradient Descent}\label{sec:gradient_descent}

Gradient based optimizations methods are of great importance to
NNs as they are most common method of training these models. They
are tasked with minimizing or maximizing some function $f(\bm{x})$ which
is oftenly called \textbf{objective function}. In NN training
scenarios, where the goal is to minimize it the same function is also
commonly called a \textbf{cost}, \textbf{loss} or \textbf{error}
function\cite{book:Goodfellow}.

Gradient descent is a method of minimizing a function $f(x)$ and
finding a local minimum, given that its differentiable. The
derivative $f'(x)$ is the slope of $f(x)$ at $x$, so it specifies
how a change in x would provide a step towards the local minimum. For instance,
for small values of $\epsilon$, $f(x - \epsilon \sgn (f'(x)))$\footnote{
  $\sgn$ is the \textit{signum function}, a piecewise function which returns
  the sign of its input or 0 if input is 0. (i.e. $\sgn(-1) = -1$ and $\sgn(12) = 1$).
} is less than $f(x)$ and traversing the slope to ever decreasing
values if possible through following the direction with the opposite
sign of the derivate. This method is called \textbf{gradient descent}
and it was first proposed by Cauchy \cite{article:Cauchy} in 1847.
\begin{figure}[h!]
  \centering
  \input{tikz_figures/chap_nn/gradient_descent_3d.tex}
  \caption{Gradient descent in three dimensional space}
  \label{fig:gradient_descent_2d}
\end{figure}

\begin{definition}
  Consider a multi-variable function $F(\bm{x})$ which is \textbf{defined}
  and \textbf{differentiable} in a neighborhood of a point $a$. The value of
  $F(\bm{x})$ will decrease the fastest when moving from $a$ towards the
  negative gradient direction of $F$, which is $\bm{-\nabla} F(\bm{a})$.
  Thus when:
  \begin{equation}
    \label{eq:grad_simple}
    \bm{a}_{n+1} = \bm{a}_n - \gamma \nabla F(\bm{a}_n)
  \end{equation}
  then $F(\bm{a}_n) \geq F(\bm{a}_{n+1})$ and therefore the values
  of $F(\bm{a})$ move towards the local minimum. A sequence
  $\bm{x_0}, \bm{x_1}, \bm{x_2}, ... \bm{x_m}$ that follows the rule
  set by \eref{eq:grad_simple} will lead to the monotic sequence
  $F(\bm{x}_0) \geq F(\bm{x}_1) \geq F(\bm{x}_2), ...$ and the
  sequence $\bm{x_n}$ will converge to the local minimum.
  If some special choices are made for $\gamma$\footnotemark{} the function is
  guaranteed to reach a local minimum. Additionaly, if the function
  is \textit{convex} local minima are global minima and gradient descent
  converges to a global solution.

  For a function to be convex, a line segment connecting two of its points
  must lay on or above its curve. Mathematically for two points $x_1$ and $x_2$,
  this can be expressed as
  \begin{equation}
    \label{eq:convex_func}
    f(\lambda x_1 + (1 - \lambda)x_2) \leq \lambda f(x_1) + (1-\lambda)f(x_2)
  \end{equation}
  where $\lambda$ is a location on a section line and $0 \leq \lambda \leq 1$.
\end{definition}

\footnotetext{$\gamma$ in machine learning is also known as the ``learning rate''
  and its one of the hypermateres of NNs. Special choices made here include a selection
  of $\gamma$ via line search which satisfies the Wolfe conditions or the Barzilai-Borwein
  method \cite{book:optimization}
}


\subsection{Stochastic Gradient Descent (SGD)}\label{sec:stoch_grad_desc}



\newpage
\subsection{Types of the most common ANNs}


\subsubsection*{Common FNNs}

\textbf{Single-layer Perceptron} 
% In feedforward neural networks, information flows from the input
% \textbf{$x$} layer towards the output


\subsection{Training}



\newpage
\subsection{Convolutional Neural Networks}
\newpage

